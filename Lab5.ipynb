{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f5eea2-aa1c-4542-914a-21241503eed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Attribute\n",
      "\n",
      "Multiple Attributes\n",
      "Linear Regression with Multiple Features:\n",
      "Coefficient: [125994.29546869 116163.97739098 125428.8726733  126693.19071667\n",
      " 127851.71527219 121743.87100719 118826.78054845 124321.19371499\n",
      " 127388.37865968 130890.98031079 125174.53063691 122514.97808261\n",
      " 126376.98707324 133173.29365451 124189.061878   128723.07806875\n",
      " 116439.53676112 116962.44394161 100958.60201518 124427.35081834\n",
      "  98341.14418311 128603.35393494 125051.82430029 132922.07705101\n",
      " 121694.27517962 126475.05224921 115693.7377141  126145.63384135\n",
      " 127910.82085974 173761.5505393  136493.87820196 127655.11681159\n",
      " 121810.83187495 138242.33733351 121587.24828824 127540.09721321\n",
      " 122190.30711467 133379.69669525 131739.67334345 134485.72467118\n",
      " 132795.81772781 123157.36225309 130789.38898051 127206.69510942\n",
      " 128985.69388029 127404.75417478 124582.84682939 127560.52866177\n",
      " 138012.46636972 120306.38374853 128507.21381102 126167.09402043\n",
      " 125040.46508338 124472.5291117  130626.4116541  118389.69590805\n",
      " 125158.99513041 135452.14900854 135868.88761695 134011.62971391\n",
      " 126774.17278117 126450.42970969 164774.41127004 136297.24014451\n",
      " 106326.96930637 125141.70077078 128356.16041751 118003.48086907\n",
      " 124655.52404519 117474.96494358 121722.45232959 130717.64466833\n",
      " 127625.09911885 116763.49014944 129034.91742173 126917.56447212\n",
      " 135872.98914666 136429.80385833 125985.31221351 132246.30884033\n",
      " 126100.02260587 129917.26943317 134257.6857624  122745.4934961\n",
      " 123384.14333769 129532.65414855 122578.66671433 117917.73076214\n",
      " 125390.89277688 137500.45187984 124882.18294111 123687.26240318\n",
      " 123911.70778015 127770.56127246 105614.70283348 119400.09687064\n",
      " 125960.47801399 127986.58757098 118295.7537558  180639.69920017\n",
      " 132637.28220251 128843.20152071 126400.84826442 123664.78815722\n",
      " 125268.55824602 126933.7265887  124203.02997968 132642.35127488\n",
      " 129588.1445193  123727.25830264 132489.78323527 128317.24553558\n",
      " 120563.66430651 125091.03667282 118866.72823553 119321.84107785\n",
      " 120672.60694105 117389.7111408  123907.45652767 122675.12134154\n",
      " 127694.75296362 130758.13270618 126195.26540755 131286.6364181\n",
      " 128815.86428484 149139.41522372 122126.549878   202152.39783223\n",
      " 122541.07056818 115646.74745018 132546.66612289 119684.70246939\n",
      " 120307.98682942 132383.35390659 131366.12742854 129042.0843113\n",
      " 120259.22736457 127160.8281788  122792.2969945  123158.92886104\n",
      " 135235.92186776 117048.26209753 118666.38278613 121219.324107\n",
      " 118482.59637397 110582.63997318 121882.37968827 134381.25865646\n",
      " 121814.69306079 114498.58082659 138274.88775196 117741.24390977\n",
      " 123672.28171777 123899.19221108 129989.84510079 120330.42012718\n",
      " 118447.95488333 156210.15116646 118806.58174379 133513.49823093\n",
      " 116768.86416404 129509.96482726 129161.48704378 114531.93036942\n",
      " 121104.22309593 147230.4581763  137107.71759885 130608.13194967\n",
      " 124475.69809894 138529.90904882 130878.99733596 128245.59294179\n",
      " 128031.4942996  128699.72996309 112474.07431121 140005.82240897\n",
      " 112717.11181073 124588.69268785 135636.01248662 134435.80586109\n",
      " 123214.86733289 135379.2358129  126633.66033797 129719.46172292\n",
      " 138791.51447692 128577.92468757 119008.5215551  122377.14935261\n",
      " 120478.83593425 115964.30486274 115115.28275114 114231.71170863\n",
      " 131046.94324212 126288.08160242 135028.99555158 125454.42228922\n",
      " 124603.18305401 129650.477474   132075.84248458 133762.06710377\n",
      " 107268.47601981 118878.21881007 122801.60159407 129802.28233594\n",
      " 121330.30876489 129400.21674661 128527.82099865 128872.60523482\n",
      " 125602.37527649 128164.65216814 125526.42012978 133077.30777697\n",
      " 125226.29060103 125745.02377965 133344.4939929  121555.71815058\n",
      " 123479.45572492 120184.23601119 120626.22595518 131488.6136409\n",
      " 115142.90528534 131894.74851461 114981.49252365 549401.88480019\n",
      " 127045.76241871 121131.60758604 124853.91464366 121675.97610649\n",
      " 122976.17498266 150479.11994587 130630.26917025 118482.85456813\n",
      " 108819.10507468 116954.35895257 117472.20033657 128614.67485119\n",
      " 111006.34413451 124882.10269376 119943.45361864 124932.23489662\n",
      " 125346.31076012 120906.194031   121666.54046131 123763.88490035\n",
      " 124294.04321512 111130.93828845 131035.1277397  128812.8400804\n",
      " 128432.40104967 220166.80358313 115478.4698211  122474.64149524\n",
      " 126382.03292304 122883.56074061 127333.60135306 126178.9508407\n",
      " 103298.62466156 119072.26267971 133819.70865774 123712.99493025\n",
      " 124222.32078922 123098.75614837 129627.0852083  121319.64269207\n",
      " 132890.96490704 131140.53277093 115575.97912584 135816.14799135\n",
      " 118255.11783918 125021.48268297 126061.71088999 130806.5694891\n",
      " 125578.9629681  118423.02267998 129466.04176505 137401.48182501\n",
      " 129981.13283245 129044.50965619 127702.70918586 120723.05846859\n",
      " 128644.69702769 120997.69441724 116728.78436163 119410.16299209\n",
      " 125272.20187961 127855.29265522 126010.94721832 119852.8832642\n",
      " 126168.77517295 128280.86730398 127872.70036797 125269.61190807\n",
      " 127588.2463188  124489.88693671 101144.89160364 124837.97530019\n",
      " 115420.75010323 125391.78698413 131336.87419105 123142.46745814\n",
      " 119389.98962459 129059.4530754  132458.79057996 127307.85276099\n",
      " 104072.31143762 130613.98972094 126805.9331047  121046.69069844\n",
      " 128773.8989335  128004.33296713 118638.55842691 123456.550629\n",
      " 135824.61655684 125419.00770828 122419.09668201 130811.55367279\n",
      " 119398.8314723  123660.58648636 126921.48148658 468183.39109885\n",
      " 124811.9990116  120299.02345356 128697.27311703 122854.39320186\n",
      " 126400.46821149 116775.98645588 120847.71961824 120141.99646853\n",
      " 141754.12156714 116147.66050692 126961.91622279 123960.99137205\n",
      " 132689.59197652 123073.8568423  127347.13196902 142897.35764609\n",
      " 125762.59266662 122696.36004713 160170.12047904 128386.85032739\n",
      " 126832.37505628 191256.41663863 123901.31586421 127494.02314996\n",
      " 130443.50991922 128029.88522692 118736.92711812 112698.86037263\n",
      " 129181.80816017 126298.20437318 130718.23994169 131368.47754423\n",
      " 127536.43793319 126212.16270098 111035.18350557 117657.15952527\n",
      " 121805.38729508 128065.2714937  125453.93956277 119110.1300834\n",
      " 138814.94542625 121605.14733306 120115.48401022 138314.10985987\n",
      " 125505.88373446 130780.94390079 124952.01832345 123607.57321657\n",
      " 125478.88176708 127029.06456917 119151.73676426 122461.36275213\n",
      " 136163.32122044 118833.36219701 123870.90153592 130363.57110259\n",
      " 129415.17636504 124081.82391716 123542.13632839 113960.59481613\n",
      " 120234.37773885 125509.43947081 118157.13457282 129950.02827835]\n",
      "Intercept: 7969.081667329891\n",
      "First 5 Predictions (Train): [3.55017289 3.36154227 3.02889186 3.76962816 4.02814745]\n",
      "First 5 Predictions (Test): [3.32568682 6.02209602 2.3354061  1.55342411 4.70249171]\n",
      "\n",
      "Linear Regression Metrics with Multiple Features:\n",
      "Train MSE: 0.34451743761481807\n",
      "Test MSE: 1.8349981045537047\n",
      "Train RMSE: 0.5869560780968351\n",
      "Test RMSE: 1.354621018792232\n",
      "Train MAPE: 24193396989073.82\n",
      "Test MAPE: 12819173071682.21\n",
      "Train R²: 0.7483586477151474\n",
      "Test R²: -0.3331670644745337\n",
      "\n",
      "Classification with Multiple Features:\n",
      "Coefficient: [[-4.06071418e-01 -3.02915350e-01  1.23334022e-01  1.96894385e-01\n",
      "  -8.39490556e-01  7.74438602e-02  6.15855432e-01  7.58754363e-02\n",
      "  -1.75491561e-01  2.96468494e-01 -2.94114333e-01  3.31694638e-01\n",
      "  -5.01690352e-01  4.40637872e-01 -5.44462927e-01 -4.22668266e-02\n",
      "  -1.49549529e-01  4.87361164e-02  5.65051685e-01 -1.40290354e-01\n",
      "   4.44380957e-01 -4.93916556e-01  4.99335166e-01 -1.26648593e-01\n",
      "  -4.49320284e-01 -2.29842812e-01  4.29660497e-01  1.13117778e+00\n",
      "  -4.35930692e-01  1.63087401e-01 -1.14233918e-01 -3.13340098e-01\n",
      "  -3.36584920e-01 -8.31294162e-02  4.73801901e-01  2.02300515e-01\n",
      "  -3.87552389e-01 -9.57690670e-01  1.25456285e-01  2.07762483e-01\n",
      "   1.96658030e-01 -3.52431657e-01 -5.82464704e-01 -1.51453656e-01\n",
      "  -4.83315580e-01 -3.86462970e-01  1.33808286e-01  2.09064178e-02\n",
      "  -1.83984923e-01  1.04668727e+00 -1.94929377e-01 -1.76391979e-01\n",
      "   5.96642947e-01 -7.69861071e-01  2.71270864e-01 -1.01994869e+00\n",
      "  -1.09664277e+00  7.45492426e-02 -2.91379656e-01  3.37499256e-01\n",
      "   3.22267522e-01 -8.25007703e-03  3.18152299e-02 -1.17113691e-01\n",
      "  -7.93365187e-01  4.14336328e-02  1.78850664e-03  6.44752249e-02\n",
      "   3.82872138e-01 -4.30502292e-01  2.70121957e-01 -6.26310466e-01\n",
      "   7.03727053e-01 -4.63371331e-01 -1.27803058e-01  5.18009019e-01\n",
      "   5.22271885e-01  7.85567428e-02 -7.99491033e-01 -2.44523248e-01\n",
      "  -2.46403734e-01  2.16981788e-01 -5.65573268e-01 -1.33821647e-01\n",
      "  -2.95036870e-01 -5.54150559e-01  3.00143810e-01  1.94813420e-01\n",
      "  -2.69269836e-01 -6.40929825e-01  1.28494022e-02 -3.21631102e-01\n",
      "   2.55210912e-01  3.73762223e-01 -2.03803352e-01  2.84115474e-01\n",
      "  -6.17437130e-01 -1.37121223e-01  3.40117902e-02 -6.19914428e-01\n",
      "  -5.77833500e-01 -1.64676102e-01  5.88461233e-01  4.58142612e-01\n",
      "  -4.77181350e-01 -1.18645799e+00  1.41726708e-01  9.59661959e-02\n",
      "   5.28775947e-01 -7.88482341e-01 -5.59805133e-01 -2.78325470e-01\n",
      "   1.20990408e+00 -8.39242759e-02 -3.88940769e-02 -2.87733471e-01\n",
      "   2.82780137e-01  4.00882929e-01  8.03787732e-02  4.05323628e-01\n",
      "   1.94476799e-01  2.37668409e-01  1.59105334e-02 -3.36580321e-01\n",
      "   1.03066007e+00  4.53078419e-01  1.93928825e-01  3.09620751e-01\n",
      "   5.27832307e-01  9.11933474e-01  5.56285270e-01  2.62282559e-01\n",
      "  -5.09539898e-01 -2.12065769e-01  7.53000071e-02  7.32190118e-02\n",
      "  -3.98910524e-01  1.76093990e-01 -7.49888797e-03  3.78566975e-01\n",
      "   2.70556735e-01 -6.06405959e-01  2.70672383e-02 -4.78234584e-01\n",
      "  -1.24081147e+00  5.39658705e-01  6.57662455e-01  6.36795794e-01\n",
      "   4.03941443e-01 -2.39662189e-01  3.23707487e-01  3.31830299e-01\n",
      "  -6.02450175e-01 -9.47590501e-02 -2.51228465e-01  1.12917792e-01\n",
      "   2.35385368e-02  8.77054660e-02 -2.52927486e-01 -2.24506525e-01\n",
      "   5.93951434e-01 -4.67703257e-01  3.79844019e-01  7.07052703e-02\n",
      "   1.37788332e-01  2.59615600e-01 -1.66602325e-01  1.78698340e-01\n",
      "  -3.72028582e-01  3.75964370e-01  1.06803549e-01 -1.23912765e-03\n",
      "   7.98275977e-02  6.17122980e-01  2.40153904e-01 -2.90982998e-01\n",
      "   2.96746709e-01 -1.33995776e-01 -4.08226501e-03  3.20246601e-01\n",
      "  -2.80984867e-01 -2.10726290e-01  7.53751473e-01 -1.65846560e-01\n",
      "  -4.74652600e-01  5.01582930e-01  3.00836817e-01  4.72167570e-01\n",
      "  -1.97013365e-01 -1.70240130e-01 -7.59747760e-01  3.69334397e-02\n",
      "  -1.64256091e-01 -2.84423886e-01  2.77803440e-01  1.95748277e-01\n",
      "   2.63347851e-01 -2.96825869e-01  2.47538633e-01  2.01250191e-01\n",
      "   3.57916623e-01  3.00026102e-01  7.28952763e-01  1.34110614e-01\n",
      "   6.87842842e-02  2.80448659e-01  5.59008050e-01 -6.88941514e-01\n",
      "   4.29397497e-01  8.67156012e-02 -1.09267852e+00 -2.81160411e-01\n",
      "  -3.90245719e-01  3.43029462e-01  3.12813953e-03 -1.55970977e-01\n",
      "   8.23171891e-01  3.42219098e-01 -7.88384108e-01  5.55272793e-01\n",
      "   6.37808959e-03 -5.82023903e-01  1.43475803e-01 -2.63260642e-01\n",
      "  -5.16886886e-01  2.52664588e-01 -8.72175262e-02 -4.83174728e-01\n",
      "   1.26098678e-01  1.69924338e-01 -2.45758206e-02  9.15244991e-01\n",
      "   8.65718158e-02  1.84357290e-01 -2.42385475e-01 -1.75964374e-01\n",
      "   5.01444379e-01 -3.10118079e-01 -9.47565631e-01  6.76469524e-01\n",
      "   2.33557512e-01 -5.29248198e-01  9.16144863e-01 -1.21776777e-01\n",
      "  -7.21700244e-01 -1.83377132e-01 -2.05640221e-01 -6.50178591e-01\n",
      "   7.12219201e-01  4.23820464e-01  1.03294163e+00  4.83474522e-01\n",
      "  -1.20064475e+00 -2.36916635e-01  1.27402024e-02 -5.52184066e-01\n",
      "   7.17582529e-02 -1.39801035e-02  8.83235253e-01  1.05665042e-01\n",
      "   2.01845323e-01  2.46425528e-02  2.34495472e-01 -7.62944609e-02\n",
      "  -2.33530677e-03  3.32321152e-01 -2.05884597e-01  1.67481560e-01\n",
      "  -5.05739695e-01 -1.82689907e-01  1.83265195e-02 -3.90102236e-01\n",
      "  -4.02900419e-02 -2.85001157e-01  3.72810720e-01  7.89869848e-02\n",
      "  -8.82227939e-02 -2.40336058e-01 -9.30077328e-02  9.03774264e-02\n",
      "  -1.08851620e-01  1.78534008e-01  5.54404770e-01 -2.14481752e-01\n",
      "   5.04475207e-01 -5.26339958e-01  2.93076790e-01 -2.72897817e-01\n",
      "  -1.01548243e-01 -1.63429443e-01 -5.68377604e-01 -5.31882772e-01\n",
      "   1.05172284e-01  2.28925753e-01 -5.20086139e-01 -3.43588009e-01\n",
      "   1.34802321e-01 -7.47207145e-02  1.08486143e+00 -8.23358804e-02\n",
      "  -3.44379680e-01  3.41304788e-01  1.21015712e-01  5.52717172e-01\n",
      "  -5.20697115e-01  6.08489767e-01 -2.91240938e-01 -1.21693570e-01\n",
      "   6.22046515e-01  2.66044352e-01 -2.83507033e-01  2.14023054e-01\n",
      "   3.27873003e-01 -3.32637586e-01  4.24927393e-02  1.89506676e-03\n",
      "  -3.92234496e-01  6.31923351e-02 -1.16240738e-01  1.11968434e-01\n",
      "   5.00459234e-01 -6.27574467e-01 -7.85848147e-01  5.75423716e-01\n",
      "   8.43402213e-01 -8.00549419e-01  1.96360039e-01 -1.04747558e+00\n",
      "   4.22853372e-01 -5.07200913e-02  1.64945599e-01  2.79079423e-01\n",
      "   1.57279165e-01 -2.30645091e-01  2.50907465e-01 -5.94170790e-01\n",
      "  -5.28809237e-03 -4.35776365e-01 -2.75547037e-02 -7.72157551e-02\n",
      "   2.94448645e-01 -6.43285458e-02 -5.69614604e-01  2.31130881e-01\n",
      "  -2.08187585e-01  1.23008807e-01  5.97619174e-01 -7.85614346e-01\n",
      "  -1.55050418e-01 -7.12775821e-01  5.75501657e-01 -4.83312474e-01\n",
      "   6.98681042e-01  5.25650653e-02 -2.15233835e-01  2.22051981e-01\n",
      "  -2.68351837e-01  1.06767572e+00 -1.83764443e-01  9.69464293e-01\n",
      "   6.01344782e-01  2.34898465e-01  7.06267493e-01 -2.88965168e-01\n",
      "   2.50218280e-01 -3.70203159e-01  3.96726290e-02 -2.06785022e-02\n",
      "   4.06287632e-01 -1.07519462e+00 -6.11865797e-02  6.93641588e-01\n",
      "  -9.74980670e-02 -4.84995320e-01  5.98099262e-01 -3.46196986e-01\n",
      "  -1.37822717e-01  1.77252738e-01 -5.37067881e-01  4.75346236e-01\n",
      "   8.17638895e-02 -4.09103521e-02 -2.14151504e-02  7.43201791e-02]]\n",
      "Intercept: [-5.20111955]\n",
      "First 5 Predictions (Train): [0 0 0 0 0]\n",
      "First 5 Predictions (Test): [0 1 0 0 1]\n",
      "\n",
      "Classification Report (Train) with Multiple Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       681\n",
      "           1       0.85      0.48      0.62       219\n",
      "\n",
      "    accuracy                           0.85       900\n",
      "   macro avg       0.85      0.73      0.76       900\n",
      "weighted avg       0.85      0.85      0.84       900\n",
      "\n",
      "\n",
      "Classification Report (Test) with Multiple Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       181\n",
      "           1       0.61      0.49      0.54        45\n",
      "\n",
      "    accuracy                           0.84       226\n",
      "   macro avg       0.75      0.71      0.72       226\n",
      "weighted avg       0.83      0.84      0.83       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def a1(file):\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Splitting the data into train and test sets\n",
    "    X = df[['embed_0']]\n",
    "    y = df['output']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Linear Regression\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_train_pred_reg = reg.predict(X_train)\n",
    "    y_test_pred_reg = reg.predict(X_test)\n",
    "    \n",
    "    # Classification\n",
    "    y_train_class = y_train.apply(lambda x: 1 if x > 4 else 0)\n",
    "    y_test_class = y_test.apply(lambda x: 1 if x > 4 else 0)\n",
    "    clf = LogisticRegression().fit(X_train, y_train_class)\n",
    "    y_train_pred_clf = clf.predict(X_train)\n",
    "    y_test_pred_clf = clf.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "        \"reg_model\": reg,\n",
    "        \"X_train\": X_train, \"X_test\": X_test,\n",
    "        \"y_train\": y_train, \"y_test\": y_test,\n",
    "        \"y_train_pred_reg\": y_train_pred_reg, \"y_test_pred_reg\": y_test_pred_reg,\n",
    "        \"clf_model\": clf,\n",
    "        \"y_train_class\": y_train_class, \"y_test_class\": y_test_class,\n",
    "        \"y_train_pred_clf\": y_train_pred_clf, \"y_test_pred_clf\": y_test_pred_clf\n",
    "    }\n",
    "\n",
    "def a2(results):\n",
    "    # Linear Regression Metrics\n",
    "    mse_train = mean_squared_error(results[\"y_train\"], results[\"y_train_pred_reg\"])\n",
    "    mse_test = mean_squared_error(results[\"y_test\"], results[\"y_test_pred_reg\"])\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    mape_train = mean_absolute_percentage_error(results[\"y_train\"], results[\"y_train_pred_reg\"])\n",
    "    mape_test = mean_absolute_percentage_error(results[\"y_test\"], results[\"y_test_pred_reg\"])\n",
    "    r2_train = r2_score(results[\"y_train\"], results[\"y_train_pred_reg\"])\n",
    "    r2_test = r2_score(results[\"y_test\"], results[\"y_test_pred_reg\"])\n",
    "\n",
    "    return {\n",
    "        \"mse_train\": mse_train, \"mse_test\": mse_test,\n",
    "        \"rmse_train\": rmse_train, \"rmse_test\": rmse_test,\n",
    "        \"mape_train\": mape_train, \"mape_test\": mape_test,\n",
    "        \"r2_train\": r2_train, \"r2_test\": r2_test\n",
    "    }\n",
    "\n",
    "def a3(file):\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Splitting the data into train and test sets\n",
    "    X = df.drop(columns=['output'])  # Use all attributes except 'output'\n",
    "    y = df['output']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Linear Regression\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_train_pred_reg = reg.predict(X_train)\n",
    "    y_test_pred_reg = reg.predict(X_test)\n",
    "    \n",
    "    # Classification\n",
    "    y_train_class = y_train.apply(lambda x: 1 if x > 4 else 0)\n",
    "    y_test_class = y_test.apply(lambda x: 1 if x > 4 else 0)\n",
    "    clf = LogisticRegression().fit(X_train, y_train_class)\n",
    "    y_train_pred_clf = clf.predict(X_train)\n",
    "    y_test_pred_clf = clf.predict(X_test)\n",
    "    \n",
    "    results = {\n",
    "        \"reg_model\": reg,\n",
    "        \"X_train\": X_train, \"X_test\": X_test,\n",
    "        \"y_train\": y_train, \"y_test\": y_test,\n",
    "        \"y_train_pred_reg\": y_train_pred_reg, \"y_test_pred_reg\": y_test_pred_reg,\n",
    "        \"clf_model\": clf,\n",
    "        \"y_train_class\": y_train_class, \"y_test_class\": y_test_class,\n",
    "        \"y_train_pred_clf\": y_train_pred_clf, \"y_test_pred_clf\": y_test_pred_clf\n",
    "    }\n",
    "    \n",
    "    metrics = a2(results)\n",
    "    \n",
    "    # Print Linear Regression Results\n",
    "    print(\"Linear Regression with Multiple Features:\")\n",
    "    print(\"Coefficient:\", results[\"reg_model\"].coef_)\n",
    "    print(\"Intercept:\", results[\"reg_model\"].intercept_)\n",
    "    print(\"First 5 Predictions (Train):\", results[\"y_train_pred_reg\"][:5])\n",
    "    print(\"First 5 Predictions (Test):\", results[\"y_test_pred_reg\"][:5])\n",
    "    \n",
    "    # Print Linear Regression Metrics\n",
    "    print(\"\\nLinear Regression Metrics with Multiple Features:\")\n",
    "    print(\"Train MSE:\", metrics[\"mse_train\"])\n",
    "    print(\"Test MSE:\", metrics[\"mse_test\"])\n",
    "    print(\"Train RMSE:\", metrics[\"rmse_train\"])\n",
    "    print(\"Test RMSE:\", metrics[\"rmse_test\"])\n",
    "    print(\"Train MAPE:\", metrics[\"mape_train\"])\n",
    "    print(\"Test MAPE:\", metrics[\"mape_test\"])\n",
    "    print(\"Train R²:\", metrics[\"r2_train\"])\n",
    "    print(\"Test R²:\", metrics[\"r2_test\"])\n",
    "    \n",
    "    # Print Classification Results\n",
    "    print(\"\\nClassification with Multiple Features:\")\n",
    "    print(\"Coefficient:\", results[\"clf_model\"].coef_)\n",
    "    print(\"Intercept:\", results[\"clf_model\"].intercept_)\n",
    "    print(\"First 5 Predictions (Train):\", results[\"y_train_pred_clf\"][:5])\n",
    "    print(\"First 5 Predictions (Test):\", results[\"y_test_pred_clf\"][:5])\n",
    "    \n",
    "    # Print Classification Report\n",
    "    print(\"\\nClassification Report (Train) with Multiple Features:\")\n",
    "    print(classification_report(results[\"y_train_class\"], results[\"y_train_pred_clf\"]))\n",
    "    print(\"\\nClassification Report (Test) with Multiple Features:\")\n",
    "    print(classification_report(results[\"y_test_class\"], results[\"y_test_pred_clf\"]))\n",
    "\n",
    "def main():\n",
    "    file = r\"C:\\Users\\Admin\\Downloads\\training_mathbert 4.xlsx\"\n",
    "    \n",
    "    # Train the models and get predictions for single attribute\n",
    "    print(\"Single Attribute\")\n",
    "    results = a1(file)\n",
    "    metrics = a2(results)\n",
    "    \n",
    "    # Train the models and get predictions for multiple attributes\n",
    "    print(\"\\nMultiple Attributes\")\n",
    "    a3(file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22e2d8-ef27-4291-9049-ae1ab8bcd02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
